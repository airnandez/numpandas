{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework pandas (with answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "    <td><a href=\"https://colab.research.google.com/github/airnandez/numpandas/blob/master/exam/2020-exam-with-answers.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a></td>\n",
    "    <td><a href=\"https://mybinder.org/v2/gh/airnandez/numpandas/master?filepath=exam%2F2020-exam-with-answers.ipynb\">\n",
    "  <img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Launch Binder\"/>\n",
    "</a></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Author: Fabio Hernandez*\n",
    "\n",
    "*Last updated: 2020-03-19*\n",
    "\n",
    "*Location:* https://github.com/airnandez/numpandas/exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "## Instructions\n",
    "\n",
    "For this excercise we will use a public dataset titled **\"Demandes de valeurs foncières géolocalisées\"** available [here](https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres-geolocalisees/). This dataset contains information about registered real state transactions (_mutations immobilières_) in France over several years. There is a file per year. The structure of the files and the semantics of each column are documented at its source.\n",
    "\n",
    "For your convenience, this notebook is prepared with code for downloading the dataset from its source, loading it into memory as a **pandas** dataframe and with some cleaning and helper functions. Your mission is execute the provided cells and to write the code to answer the questions below.\n",
    "\n",
    "You must not modify the code provided. You must provide code for answering the questions, following the instructions for each one of them.\n",
    "\n",
    "When you have finished, please save your notebook in the form of a `.ipynb` file and send it by e-mail to your instructor according to the indications you received by e-mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function for downloading data to a local file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download(url: str, path: str):\n",
    "    \"\"\"Download file at url and save it locally at path.\"\"\"\n",
    "    with requests.get(url, stream=True) as resp:\n",
    "        if not resp.ok:\n",
    "            raise f'Could not find file at URL {url}'\n",
    "            \n",
    "        mode, data = 'wb', resp.content\n",
    "        if 'text/plain' in resp.headers['Content-Type']:\n",
    "            mode, data = 'wt', resp.text\n",
    "        with open(path, mode) as f:\n",
    "            f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data files, one per year, for the period 2016-2021, both inclusive. We store the downloaded data in the directory `../data` relative to the location of this notebook. If a file has been already been downloaded, don't download it again. The total amount of data to download is about 400 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create destination directory\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "\n",
    "# Download files\n",
    "data_source = \"https://files.data.gouv.fr/geo-dvf/latest/csv\"\n",
    "\n",
    "for year in range(2016, 2022):\n",
    "    # Build the URL and the destination file path\n",
    "    url = f'{data_source}/{year}/full.csv.gz'\n",
    "    path = os.path.join('..', 'data', f'{year}-mutations-immobilieres.csv.gz')\n",
    "    \n",
    "    # If file already exists don't download it again\n",
    "    if not os.path.isfile(path) :\n",
    "        print(f'downloading {url} to local file {path}')\n",
    "        download(url, path)\n",
    "    else:\n",
    "        print(f'local file {path} already exists. Skipping download...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what files we have for our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(os.path.join('..', 'data', '*-mutations-immobilieres.csv.gz'))\n",
    "print('\\n'.join(f for f in file_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Load the dataset\n",
    "\n",
    "Load the dataset (i.e. all the files `../data/*-mutations-immobilieres.csv.gz`) to a **pandas** dataframe. Here we select the columns we want to load. The information about the format and contents of each column is available [here](https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres-geolocalisees/). Please make sure you are familiar with that information which you will need for analysing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the names of the columns present in the source files.\n",
    "# We are not interested in analysing the commented columns, so we don't tell\n",
    "# pandas to not load them\n",
    "columns = (\n",
    "    'id_mutation',\n",
    "    'date_mutation',\n",
    "    'numero_disposition',\n",
    "    'nature_mutation',\n",
    "    'valeur_fonciere',\n",
    "    'adresse_numero',\n",
    "    'adresse_suffixe',\n",
    "    'adresse_nom_voie',\n",
    "    'adresse_code_voie',\n",
    "    'code_postal',\n",
    "    'code_commune',\n",
    "    'nom_commune',\n",
    "    'code_departement',\n",
    "#   'ancien_code_commune',\n",
    "#   'ancien_nom_commune',\n",
    "#   'id_parcelle',\n",
    "#   'ancien_id_parcelle',\n",
    "#   'numero_volume',\n",
    "    'lot1_numero',\n",
    "    'lot1_surface_carrez',\n",
    "    'lot2_numero',\n",
    "    'lot2_surface_carrez',\n",
    "    'lot3_numero',\n",
    "    'lot3_surface_carrez',\n",
    "    'lot4_numero',\n",
    "    'lot4_surface_carrez',\n",
    "    'lot5_numero',\n",
    "    'lot5_surface_carrez',\n",
    "    'nombre_lots',\n",
    "    'code_type_local',\n",
    "    'type_local',\n",
    "    'surface_reelle_bati',\n",
    "    'nombre_pieces_principales',\n",
    "#   'code_nature_culture',\n",
    "    'nature_culture',\n",
    "#   'code_nature_culture_speciale',\n",
    "#   'nature_culture_speciale',\n",
    "    'surface_terrain',\n",
    "#   'longitude',\n",
    "#   'latitude'\n",
    ")\n",
    "\n",
    "# These are the types we want pandas to use for each column\n",
    "column_types = {\n",
    "    'id_mutation': object,\n",
    "    'adresse_suffixe': str,\n",
    "    'adresse_numero': str,\n",
    "    'adresse_suffixe': str,\n",
    "    'adresse_nom_voie': str,\n",
    "    'adresse_code_voie': str,\n",
    "    'code_postal': str,\n",
    "    'code_commune': str,\n",
    "    'code_departement': str,\n",
    "    'ancien_code_commune': str,\n",
    "    'ancien_nom_commune': str,\n",
    "    'id_parcelle': str,\n",
    "    'ancien_id_parcelle': str,\n",
    "    'lot1_numero': str,\n",
    "    'lot2_numero': str,\n",
    "    'lot3_numero': str,\n",
    "    'lot4_numero': str,\n",
    "    'lot5_numero': str,\n",
    "    'code_type_local': str,\n",
    "    'type_local': str,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly delete our existing dataframe, if any\n",
    "try:\n",
    "    del df\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "file_paths = glob.glob(os.path.join('..', 'data', '*-mutations-immobilieres.csv.gz'))\n",
    "df = pd.DataFrame()\n",
    "for path in sorted(file_paths):\n",
    "    print(f'Loading file {path}')\n",
    "    df = df.append(pd.read_csv(path, usecols=columns, dtype=column_types, parse_dates=['date_mutation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the dimensions of the dataframe\n",
    "rows, columns = df.shape\n",
    "print(f'This dataframe has {rows:,} rows and {columns:,} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARNING:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that there may be several rows for the same transaction. All the rows part of a single transaction have the same identifier (i.e. the same value) in the `id_mutation` column as well as the same value in the column `valeur_fonciere`. For instance, there are two rows with the value `2018-2` in the `id_mutation` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['id_mutation'] == '2018-2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what **kind of transactions** are encoded in these records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(df['nature_mutation'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what **kind of properties** are these transactions about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in df['type_local'].unique():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values for filters\n",
    "Here we define some convenient constants that we can use for building masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APPARTMENT = 'Appartement'\n",
    "HOUSE      = 'Maison'\n",
    "BUSINESS   = 'Local industriel. commercial ou assimilé'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "# Questions (10 points + bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Question N° 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1a (1 point)\n",
    "How many transactions of type sale (i.e. those with value `Vente` in the column `nature_mutation`) were registered in the period covered in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_sale = df['nature_mutation'] == 'Vente'\n",
    "sales = df[is_sale]\n",
    "sales_count = sales['id_mutation'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {sales_count:,} sales in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b (1 point)\n",
    "How many sales were registered for each kind of property (i.e. `Maison`, `Dépendance`, `Appartement` and `Local industriel`) in the whole period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_count    = sales[sales['type_local'] == HOUSE]['id_mutation'].nunique()\n",
    "appt_count     = sales[sales['type_local'] == APPARTMENT]['id_mutation'].nunique()\n",
    "business_count = sales[sales['type_local'] == BUSINESS]['id_mutation'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the period covered in the dataset\n",
    "start_date, end_date = df['date_mutation'].min(), df['date_mutation'].max()\n",
    "\n",
    "# Compute the percentage of sales per kind of object\n",
    "house_pct    = 100.0 * (house_count/sales_count)\n",
    "appt_pct     = 100.0 * (appt_count/sales_count)\n",
    "business_pct = 100.0 * (business_count/sales_count)\n",
    "\n",
    "# Print the report\n",
    "print(f'Period covered: from {start_date:%Y-%m-%d} to {end_date:%Y-%m-%d}:')\n",
    "print(f'          total:  {sales_count:>10,} sales')\n",
    "print(f'         houses:  {house_count:>10,} ({house_pct:>2.0f}%)')\n",
    "print(f'    appartments:  {appt_count:>10,} ({appt_pct:>2.0f}%)')\n",
    "print(f'       business:  {business_count:>10,} ({business_pct:>2.0f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1c (2 points)\n",
    "What is the total amount of money (in million €) involved in those sales? Please remember that there may be several rows for a single transaction and within a single transaction each row has the same value in the column `valeur_fonciere`. You may want to consider grouping all the rows for the same transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'id_mutation' and take the first row of each group\n",
    "sales_by_id = sales.groupby('id_mutation').first()\n",
    "\n",
    "# Add the column 'valeur_fonciere' of each group (which is actually composed of a single row per group)\n",
    "sales_in_million_euros = sales_by_id['valeur_fonciere'].sum() / 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The total amount of money in sales was {sales_in_million_euros:,.0f} million €')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Question N° 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2a (3 points)\n",
    "Your client, a big international corporation, is looking to purchase a property for installing a retail store in the Av. des Champs Elysées, in Paris. They hire you to provide an estimation of the necessary budget to purchase a property based on the data recorded in this dataset. You should only consider transactions involving business properties with a surface bigger than 300 m², "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a view with the relevant data\n",
    "sales             = df[is_sale]\n",
    "is_business       = sales['type_local'] == BUSINESS\n",
    "is_paris_8        = sales['code_postal'] == '75008'\n",
    "is_champs_elysees = sales['adresse_nom_voie'].str.contains('AV DES CHAMPS ELYSEES', case=False)\n",
    "is_big_surface    = sales['surface_reelle_bati'] > 300\n",
    "\n",
    "sales_champs_elysees = sales[is_business & is_paris_8 & is_champs_elysees & is_big_surface]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by transaction id\n",
    "sales_champs_elysees_by_id = sales_champs_elysees.groupby(['id_mutation'])\n",
    "\n",
    "# For each transaction (i.e. each group), compute its cost. Since every row in a single\n",
    "# group contains the same value in the column 'valeur_fonciere', we use the mean of that\n",
    "# column for each group to get the value of the whole transaction\n",
    "cost_per_transaction = sales_champs_elysees_by_id['valeur_fonciere'].mean()\n",
    "\n",
    "# For each group, sum the surfaces of all the components of the transaction\n",
    "surface_per_transaction = sales_champs_elysees_by_id['surface_reelle_bati'].sum()\n",
    "\n",
    "# Compute the average of the cost per square meter for each transaction\n",
    "mean_cost_per_sq_meter = np.mean(cost_per_transaction / surface_per_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The average observed cost per square meter, for business bigger than 300 m² is {mean_cost_per_sq_meter:,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b (3 points)\n",
    "\n",
    "Your customer also wants to know how much money was needed for the most expensive transaction and the address of the property. Can you provide them that information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the id and the cost for the biggest transaction\n",
    "cost_per_transaction = sales_champs_elysees_by_id['valeur_fonciere'].mean()\n",
    "id_mutation, max_cost = cost_per_transaction.idxmax(), cost_per_transaction.max()\n",
    "\n",
    "# Retrieve the number and address of the property\n",
    "most_expensive_sale = sales_champs_elysees[sales_champs_elysees['id_mutation'] == id_mutation]\n",
    "address = f\"{most_expensive_sale['adresse_numero'].values[0]}, {most_expensive_sale['adresse_nom_voie'].values[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The cost of the biggest sale transaction was {max_cost/1_000_000:,.0f} m€ for a property located at {address}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2c (bonus: 1 point)\n",
    "Can you tell what store is now located at the address found in your answer for question 2b?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
