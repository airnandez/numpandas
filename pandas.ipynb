{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas tutorial\n",
    "\n",
    "![pandas logo](https://pandas.pydata.org/_static/pandas_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Author: Fabio Hernandez*\n",
    "\n",
    "*Last updated: 2019-05-15*\n",
    "\n",
    "*Location:* https://github.com/airnandez/numpandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "## Introduction\n",
    "\n",
    "This is a short tutorial for helping you getting familiar with the **pandas** library, which is built on top of NumPy: you can find an introduction to NumPy in [this notebook](NumPy.ipynb).\n",
    "\n",
    "This tutorial draws inspiration, ideas and sometimes material from several publicly available sources. Please see the [Acknowledgements](#Acknowledgements) section for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "## Reference documentation\n",
    "\n",
    "The entry point to the documentation of the stable release of pandas is http://pandas.pydata.org/pandas-docs/stable. It includes a [user guide](http://pandas.pydata.org/pandas-docs/stable/user_guide/index.html), an [API reference](http://pandas.pydata.org/pandas-docs/stable/reference/index.html) and a [cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf).\n",
    "\n",
    "The [DataCamp pandas Cheat Sheet](https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf) can also be a useful resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Import\n",
    "\n",
    "**pandas** is customarily imported as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, for the examples given in this notebook we will need some packages from the Python standard library so we import them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Overview\n",
    "\n",
    "**pandas** offers three main data structures designed to facilitate the programmatic manipulation of datasets with flexibility. Those data structures are `DataFrame`, `Series` and `Index`. We will start exploring what a `DataFrame` is and what we can do with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Load the dataset\n",
    "\n",
    "Read a sample dataset, located in the `data` subdirectory, which is formatted as a sequence of lines, each line composed of series of comma-separated values. Our sample dataset contains some data about the European Union, extracted from several sources, including [Wikipedia](https://en.wikipedia.org/wiki/European_Union), [EuroStat](https://ec.europa.eu/eurostat) and the [EU Budget](http://ec.europa.eu/budget) site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Inspect a few lines of the text file containing the dataset\n",
    "head -5 \"./data/european_union.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This particular dataset uses ';' as separator, instead of the more usual ','\n",
    "df = pd.read_csv('./data/european_union.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the dimensions of the dataframe\n",
    "rows, columns = df.shape\n",
    "print(f'This dataframe has {rows} rows and {columns} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas** has built-in methods for doing I/O with files in several formats, including flat files (csv, fixed-width format, msgpack), Excel, JSON, HTML, HDF5, parquet, SQL, etc. See the [documentation](http://pandas.pydata.org/pandas-docs/stable/reference/io.html#flat-file) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Exploring the dataset contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what data is included in the dataset, you can explore the contents of the whole dataframe.\n",
    "\n",
    "**WARNING**: it is not always a good idea to display the entire dataset, depending of the size of the data. It is recommended to first inspect the size of the dataframe as done above. This dataset is small, so display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also explore a fraction of the dataset by displaying, for instance, a few rows at the begining or at the end of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 3 rows of the dataset. By default, the first 5 rows will be displayed\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also explore the last rows of the dataset or any intermediate rows, by using notation similar to the one used with NumPy arrays, on top of which **pandas** is built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 3 rows of the dataset\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the rows from position 10 up to position 14 (not included)\n",
    "df[10:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas** is designed for efficient handling of datasets organized as follows:\n",
    "\n",
    "* each observation is saved in its own row\n",
    "* each variable is saved in its own column\n",
    "\n",
    "Our sample dataset is organized in exactly that way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An aside: understanding the dataset\n",
    "\n",
    "In order to analyse any dataset, you need a good understanding of the meaning of the data. Here are the details of our sample data set:\n",
    "\n",
    "| column                                    | meaning |\n",
    "| ------------------------------------------|----------|\n",
    "| `country`                                 | name of the country, in English |\n",
    "| `country_code`                            | code of the country, as used by [Eurostat](https://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Country_codes) |\n",
    "| `accession_date`                          | date of accesion of the country to the European Union (format: yyyy-mm-dd) |\n",
    "| `population`                              | the number of persons having their usual residence in each country as of January 1st, 2018 (source: [Eurostat](https://ec.europa.eu/eurostat/tgm/table.do?tab=table&plugin=1&language=en&pcode=tps00001)) |\n",
    "| `euro_zone_member`                        | `True` if the country is member of the [Eurozone](https://en.wikipedia.org/wiki/Eurozone)  |\n",
    "| `immigration`                             | total number of long-term immigrants arriving into each country in 2017, as reported by each country (source: [Eurostat](https://ec.europa.eu/eurostat/tgm/table.do?tab=table&plugin=1&language=en&pcode=tps00176)) |\n",
    "| `emigration`                              | total number of long-term emigrants leaving from the reporting country in 2017, as reported by each country (source: [Eurostat](https://ec.europa.eu/eurostat/tgm/table.do?tab=table&plugin=1&language=en&pcode=tps00177))  | \n",
    "| `contribution_to_eu_budget_millions_euro` | contribution to the EU budget for each country (based on the GNI), for year 2017, in millions euros (source: [European Commission](http://ec.europa.eu/budget/graphs/revenue_expediture.html)) |\n",
    "| `expenditure_eu_budget_millions_euro`     | expenditure of the EU budget per country (for all programs), for year 2017, in millions euros (source: [European Commission](http://ec.europa.eu/budget/graphs/revenue_expediture.html)) |\n",
    "\n",
    "Generally speaking, in order to draw sensible conclusions from any dataset you are analysing, make sure you understand precisely what is contained in the dataset and you understand where the data comes from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `dataframe` properties\n",
    "\n",
    "You can get some information on the properties of `dataframe`. The attribute `Dataframe.columns` is an object of type `Index` (see [reference documentation](https://pandas.pydata.org/pandas-docs/stable/reference/indexing.html#index)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the columns in this dataframe\n",
    "for c in df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of values (of any type) contained in the dataframe\n",
    "print(f'This dataframe contains {df.size} values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the amount of RAM (in bytes) used for storing this dataframe contents\n",
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data\n",
    "\n",
    "Very often, the *raw* data needs some cleaning, so that we can easily manipulate them it in **pandas**. For instance, in this particular example, we need to make sure that **pandas** understands that the column `accession_date` is a date and not just a string. This is useful for comparisons and filtering, that will visit later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the types of each column in the dataframe\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column 'accession_date' to a date\n",
    "df['accession_date'] = df['accession_date'].astype('datetime64[D]')\n",
    "df['accession_date'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Selecting and filtering\n",
    "\n",
    "**pandas** provides powerful built-in tools for filtering the data row-wise and column-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a utility function we use for displaying the dataframe, which we use later\n",
    "def highlight_column(s):\n",
    "    return 'background-color: PaleGoldenrod'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select all values in a given column\n",
    "\n",
    "Selecting all the values in a column is a frequent operation we need to perform on any dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3).style.applymap(highlight_column, subset=['population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values of the column 'population' for all rows\n",
    "df['population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: it is possible to use the notation `df.population` to select all the values of the column `population`. However, this notation is not recommended since the name of the column must be a valid Python identifier for it to work. For instacnce, if the name of my column is `budget-contribution`, this notation cannot be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: This notation is NOT recommended. Use instead:: df['population']\n",
    "df.population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform operations on all the numerical values of a column, such as descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some descriptive statistics of the values in the 'population' column\n",
    "df['population'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum all the values of the column 'population'\n",
    "eu_population = df['population'].sum()\n",
    "print(f'The population of the EU is {eu_population:,} people')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also perform an operation on all the values of one (or more) columns. For instance, let's convert all the population values to millions before performing some additional operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = df['population'] / 1_000_000  # you can also use the notations 1e6 or 1000000\n",
    "min_population, max_population = population.min(), population.max()\n",
    "total_population = population.sum()\n",
    "num_countries = population.count()\n",
    "\n",
    "print(f'Least populous country has {min_population:.1f} millions')\n",
    "print(f'Most populous country has {max_population:.1f} millions')\n",
    "print(f'Total EU population is {total_population:.1f} millions located in {num_countries} countries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select rows satisfying one or more conditions\n",
    "\n",
    "You can select the rows of the dataframe that satisfy one or more conditions on the values of a column. You can use logical expressions with those conditions (i.e. using operators and, or, not) to select the rows of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the rows with value True in the column 'euro_zone_member'\n",
    "is_eurozone_member = df['euro_zone_member'] == True\n",
    "euro_zone_df = df[is_eurozone_member]\n",
    "\n",
    "euro_zone_df.style.applymap(highlight_column, subset=['euro_zone_member'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is another more compact way of expressing the same filter,\n",
    "# but is not necessarily easier to read\n",
    "euro_zone_df = df[df['euro_zone_member'] == True]\n",
    "euro_zone_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of a select operation is generally a dataframe object. You can perform operations on that dataframe as you would on any other dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the population of the eurozone\n",
    "is_eurozone_member = df['euro_zone_member'] == True\n",
    "eurozone_population = df[is_eurozone_member]['population'].sum() / 1_000_000\n",
    "print(f'The population of the Euro zone is {eurozone_population:.2f} millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the countries which joined the EU since year 1989 which adopted the Euro\n",
    "is_eurozone_member = df['euro_zone_member'] == True\n",
    "joined_since_1989  = df['accession_date'] >= datetime.datetime(1989, 1, 1)\n",
    "\n",
    "df[is_eurozone_member & joined_since_1989]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the countries which are either founder members or have a population\n",
    "# of at least 20M people\n",
    "is_founder = df['accession_date'] == datetime.datetime(1957, 3, 25)\n",
    "is_bigger_than_20m = df['population'] >= 20_000_000\n",
    "df[is_founder | is_bigger_than_20m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the populations of founder members vs. non-founder member countries\n",
    "is_founder = df['accession_date'] == datetime.datetime(1957, 3, 25)\n",
    "\n",
    "founders_population = df[is_founder]['population'].sum() / 1e6\n",
    "non_founders_population = df[~is_founder]['population'].sum() / 1e6\n",
    "\n",
    "print(f\"Founders' population:     {founders_population:.0f} millions\")\n",
    "print(f\"Non-founders' population: {non_founders_population:.0f} millions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select specific rows\n",
    "\n",
    "One of the most useful methods for selecting rows and values within a row is [DataFrame.loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html). It accepts several forms as input, but a general one is:\n",
    "\n",
    "`df.loc[rows, cols]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the entire row with data for France\n",
    "# We need to provide the index of the row we want to retrieve\n",
    "df.loc[9, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve specific columns of a given row\n",
    "df.loc[9, ['capital', 'contribution_to_eu_budget_millions_euro']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve specific columns of a range of rows\n",
    "df.loc[9:11, ['country', 'population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set a meaningful index\n",
    "\n",
    "It is convenient to use an index which is meaningful to allow us to select an entire row or specific columns within a row using a meaningful label. You can set the index of a dataframe when you load it from a file or after the dataframe is already in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the contents of the `country_code` column as the dataframe index\n",
    "# We don't want the original dataframe to be modified, so we use a new variable\n",
    "df_new = df.set_index('country_code')\n",
    "df_new.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use that more meaningful index to select the rows of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the population for countries ES and DE\n",
    "df_new.loc[['ES', 'DE'], ['population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set the index when loading the data to memory, by specifying the column number we want to use as the index of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/european_union.csv', sep=';', index_col=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## Sorting\n",
    "\n",
    "You can sort the contents of a dataframe, according to the values of a set of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the mediterranean countries, sorted according to their accession date and population\n",
    "mediterraneans = ['Spain', 'France', 'Italy', 'Slovenia', 'Croatia', 'Greece']\n",
    "is_mediterranean = df['country'].isin(mediterraneans)\n",
    "df[is_mediterranean].sort_values(by=['accession_date', 'population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also retrieve the N largest (or N smallest) rows, according to the value of some columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 countries according to their emigration values\n",
    "df.nlargest(5, columns=['emigration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Modifying the dataframe\n",
    "\n",
    "You will often need to modify the dataframe, for instance, for cleaning it, for extending it or for computing new values useful in the data analysis process.\n",
    "\n",
    "Please note that the modifications are applied to the in-memory data, not to the disk file, unless you explicitely do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some dataframe columns to use shorter names\n",
    "df = df.rename(columns={\n",
    "    # current column name                      new column name\n",
    "    'contribution_to_eu_budget_millions_euro': 'budget_contribution',\n",
    "    'expenditure_eu_budget_millions_euro':     'budget_expenditure',\n",
    "})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also extend the dataframe by creating new columns, which values may be computed using other columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the budget contribution and the budget expenditure per capita\n",
    "df['budget_contribution_per_capita'] = (df['budget_contribution'] * 1_000_000 ) / df['population']\n",
    "df['budget_expenditure_per_capita']  = (df['budget_expenditure'] * 1_000_000 ) / df['population']\n",
    "\n",
    "df.head(4).style.applymap(highlight_column, subset=['budget_contribution_per_capita', 'budget_expenditure_per_capita'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute a `Series` of values from the values in the columns of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the net contribution to the EU budget for each country\n",
    "net_contribution = df['budget_contribution_per_capita'] - df['budget_expenditure_per_capita']\n",
    "net_contribution.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The net contribution by France to the 2017 EU budget was approx. {net_contribution[\"FR\"]:.0f}€ per capita')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the methods `idxmin()` (or `idxmax()`) to retrieve the index of the minimum (or maximum) value of a column. In our case, we can use this to retrieve the country code (i.e. the value of the dataframe index) and then the country name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the code of the countries with minimum and maximum value on the\n",
    "# 'budget_expenditure' column\n",
    "expenditure = df['budget_expenditure']\n",
    "country_min_expenditure = df.loc[expenditure.idxmin(), 'country']\n",
    "country_max_expenditure = df.loc[expenditure.idxmax(), 'country']\n",
    "\n",
    "print(f'The country with lowest EU budget expenditure in 2017 was:  {country_min_expenditure}')\n",
    "print(f'The country with highest EU budget expenditure in 2017 was: {country_max_expenditure}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Serializing a dataframe\n",
    "\n",
    "You can save the contents of a dataframe to disk. **pandas** natively support several formats (see [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#serialization-io-conversion)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the (modified) dataframe to disk, in CSV format\n",
    "df.to_csv('./data/my_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "head -5 './data/my_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Grouping\n",
    "\n",
    "In some datasets, data is organized so that grouping the observations (i.e. the rows) is necessary to answer some analysis questions. **pandas** provide useful tools for grouping data based on the values of one or more columns.\n",
    "\n",
    "The data in the dataset we have been working on does not require grouping. We load a different, more complex and bigger dataset to explore how grouping works.\n",
    "\n",
    "The dataset we will use contains data about the names given to babies in France during from year 1900 to year 2017. For each given name you can find the sex of the baby (male or female), the year of birth, the department and the number of babies registered with that given name per year and per department.\n",
    "\n",
    "You can find details of this public dataset, including the exact meaning of each variable (in French),  at https://www.insee.fr/fr/statistiques/2540004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forget the dataset we have been using so far\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset. Its fields are separated by tabs.\n",
    "# We ask pandas to interpret the columns 'annais' and 'dpt' as strings to avoid error with missing\n",
    "# values\n",
    "df = pd.read_csv('./data/prenoms-fr-1900-2017.tsv.gz', sep='\\t', dtype={'annais':str, 'dpt':str})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the types of the columns dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a utility function we use for displaying the dataframe\n",
    "def highlight_missing(s):\n",
    "    missings = ('XX', 'XXXX')\n",
    "    return 'color: white; background-color: Crimson' if s in missings else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some columns to use more meaningful names\n",
    "df = df.rename(columns={\n",
    "    'sexe':      'sex',\n",
    "    'preusuel':  'name',\n",
    "    'annais':    'year',\n",
    "    'dpt':       'department',\n",
    "    'nombre':    'count'})\n",
    "\n",
    "df.head().style.applymap(highlight_missing, subset=['year', 'department'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, there are rows with missing values, which in this case are represented by the strings `XXXX` for year or `XX` for the department. For the purposes of this tutorial, we ignore those rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing department and year\n",
    "df.drop(df[df['department'] == 'XX'].index, inplace=True)\n",
    "df.drop(df[df['year'] == 'XXXX'].index, inplace=True)\n",
    "\n",
    "# Convert columns 'department' and 'year' to numeric values\n",
    "df['department'] = pd.to_numeric(df['department'])\n",
    "df['year']       = pd.to_numeric(df['year'])\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this dataset, the sex is represented as 1 for males and 2 for females\n",
    "# Define some convenient constants\n",
    "MALE = 1\n",
    "FEMALE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of babies of each sex contained in the dataset\n",
    "boys = df[df['sex'] == MALE]\n",
    "girls = df[df['sex'] == FEMALE]\n",
    "\n",
    "print(f\"Babies registered from 1900 to 2017:\")\n",
    "print(f\"   boys: {boys['count'].sum():,}\")\n",
    "print(f\"  girls: {girls['count'].sum():,}\")\n",
    "print(f\"  total: {df['count'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know how many boys were given the name **Zinedine** before an after year 1998, when France won the football world cup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinedines = boys[boys['name'] == 'ZINEDINE']\n",
    "zinedines_before_1998 = zinedines[zinedines['year'] < 1998]['count'].sum()\n",
    "zinedines_after_1998  = zinedines[zinedines['year'] >= 1998]['count'].sum()\n",
    "\n",
    "print(f\"Number of boys named 'Zinedine' in France:\")\n",
    "print(f\"   before 1998: {zinedines_before_1998: 5}\")\n",
    "print(f\"    since 1998:  {zinedines_after_1998: 5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to get more details about the years those babies were named **Zinedine**, so we group the data by year: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the \"zinedines\" per year and sum the values of column 'count' for each year\n",
    "zinedines_per_year = zinedines.groupby(['year'])['count'].sum()\n",
    "zinedines_per_year.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot to visually explore the results of the operation above. For this we use **matplotlib**. Please ignore for now the details of how to use matplotlib. We look in more detail some aspects of data visualisation in [this notebook](visualisation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (8,6)\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of \"zinedines\" as a function of the year\n",
    "zinedines_per_year.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Acknowledgements\n",
    "<a id='Acknowledgements'></a>\n",
    "\n",
    "These are the sources this notebook is based on. You are encouraged to consult them to deep further:\n",
    "\n",
    "* [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) by Jave VanderPlas (highly recommended book)\n",
    "* [10 minutes to pandas](http://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html)\n",
    "* Data School [Pandas best practices](https://youtu.be/hl-TGI4550M) (video)\n",
    "* Dunder Data's [Intro to Pandas](https://youtu.be/31wa8tmrkPU) video series\n",
    "* Python Bootcamp organised by the [Berkeley Institute for Data Science (BIDS)](https://bids.berkeley.edu) in the Fall 2016: [videos](https://bids.berkeley.edu/news/python-boot-camp-fall-2016-training-videos-available-online) and [notebooks](https://github.com/profjsb/python-bootcamp)\n",
    "* [Python for Data Analysis](https://www.oreilly.com/library/view/python-for-data/9781491957653) 2nd Edition, by Wes McKinney"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
